<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" />

    <link rel="shortcut icon" href="https://raw.githubusercontent.com/cleanlab/assets/a4483476d449f2f05a4c7cde329e72358099cc07/cleanlab/cleanlab_favicon.svg"/><meta name="generator" content="sphinx-5.1.1, furo 2022.06.21"/>
        <title>Finding Label Errors in Token Classification Datasets - cleanlab</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=40978830699223671f4072448e654b5958f38b89" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/katex-math.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">cleanlab</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a style="padding-bottom: 0px;" class="sidebar-brand centered" href="../index.html">
    
    <div class="sidebar-logo-container">
        <img class="sidebar-logo" src="https://raw.githubusercontent.com/cleanlab/assets/master/cleanlab/cleanlab_logo_only.png" alt="Logo" />
    </div>
    
    <span style="margin-bottom:0px" class="sidebar-brand-text">
        cleanlab
    </span>
    
</a>

<div class="centered">
    <a style="margin-top: 6px;" class="github-button" href="https://github.com/cleanlab/cleanlab" data-size="large" data-show-count="true"
    aria-label="Star cleanlab/cleanlab on GitHub">Star</a>
</div>
<form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1"><a class="reference internal" href="../index.html">Quickstart</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="indepth_overview.html">Cleanlab 2.0: The Workflows of Data-centric AI</a></li>
<li class="toctree-l1"><a class="reference internal" href="image.html">Image Classification with PyTorch and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="text.html">Text Classification with TensorFlow, Keras, and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="tabular.html">Classification with Tabular Data using Scikit-Learn and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="audio.html">Audio Classification with SpeechBrain and Cleanlab</a></li>
<li class="toctree-l1"><a class="reference internal" href="dataset_health.html">Find Dataset-level Issues for Dataset Curation</a></li>
<li class="toctree-l1"><a class="reference internal" href="pred_probs_cross_val.html">Computing Out-of-Sample Predicted Probabilities with Cross-Validation</a></li>
<li class="toctree-l1"><a class="reference internal" href="outliers.html">Detecting Outliers with Cleanlab and PyTorch Image Models (timm)</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiannotator.html">Find Improved Consensus Labels for Multiannotator Data</a></li>
<li class="toctree-l1"><a class="reference internal" href="faq.html">FAQ</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/classification.html">classification</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/filter.html">filter</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/rank.html">rank</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/count.html">count</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/dataset.html">dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cleanlab/multiannotator.html">multiannotator</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/benchmarking/index.html">benchmarking</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/benchmarking/noise_generation.html">noise_generation</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/experimental/index.html">experimental</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/fasttext.html">fasttext</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/mnist_pytorch.html">mnist_pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/coteaching.html">coteaching</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/experimental/cifar_cnn.html">cifar_cnn</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../cleanlab/internal/index.html">internal</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/util.html">util</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/latent_algebra.html">latent_algebra</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/label_quality_utils.html">label_quality_utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../cleanlab/internal/validation.html">validation</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Guides</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../migrating/migrate_v2.html">Migrating to v2.0</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Links</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://cleanlab.ai">Website</a></li>
<li class="toctree-l1"><a class="reference external" href="https://github.com/cleanlab/cleanlab">GitHub</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pypi.org/project/cleanlab/">PyPI</a></li>
<li class="toctree-l1"><a class="reference external" href="https://anaconda.org/Cleanlab/cleanlab">Conda</a></li>
</ul>

</div>


<!-- Start of versioning -->

<div class="sidebar-tree">
    <p class="caption" role="heading">
        <span class="caption-text">Versions</span>
    </p>
    <ul>
        <li class="toctree-l1">
            <a
                id="version_number"
                class="reference internal"
                href="/"
                >stable</a
            >
        </li>
        <li class="toctree-l1">
            <a
                id="commit_hash"
                class="reference internal"
                href="/master/"
                >developer</a
            >
        </li>
        <li class="toctree-l1">
            <a
                id="v1.0.1"
                class="reference internal"
                href="/v1.0.1/"
                >v1.0.1</a
            >
        </li>
    </ul>
</div>

<br>
<br>

<script
    type="text/javascript"
    src="/versioning.js"
></script>

<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const commit_hash = Version.commit_hash;

        document.getElementById("version_number").innerHTML =
            "stable <code class='docutils literal notranslate'><span class='pre'> (" +
            version_number +
            ")</span></code>";
        document.getElementById("commit_hash").innerHTML =
            "master <code class='docutils literal notranslate'><span class='pre'> (" +
            commit_hash.slice(0, 7) +
            "&hellip;)</span></code>";
    });
</script>

<!-- End of versioning -->

</div>
      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          

<noscript>
  <div class="admonition warning">
    <p class="admonition-title">Warning</p>
    <p>Parts of this site uses JavaScript, but your browser does not support it.</p>
  </div>
</noscript>



<!-- Start of Version Warning Banner -->

<p id="doc_ver_warning"></p>

<script
    type="text/javascript"
    src="/versioning.js"
></script>
<script type="text/javascript">
    window.addEventListener("load", () => {
        const version_number = Version.version_number;
        const path_arr = window.location.pathname.split("/");

        if (path_arr.includes("master")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This version of the documentation corresponds to the master branch of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> source code from <a href="https://github.com/cleanlab/cleanlab/">GitHub</a>. To see the documentation for the latest <code class="docutils literal notranslate"><span class="pre">pip</span></code>-installed version, click <a href="/">here</a>.</p>
            </div>`;
        } else if (!path_arr.includes(version_number) && !path_arr.includes("stable")) {
            document.getElementById("doc_ver_warning").innerHTML =
            `<div class="admonition warning">
            <p class="admonition-title">Warning</p>
            <p>This documentation is for an old version (<code class="docutils literal notranslate"><span class="pre">master</span></code>) of <code class="docutils literal notranslate"><span class="pre">cleanlab</span></code>. To see the documentation for the latest stable version (<code class="docutils literal notranslate"><span class="pre">` + version_number + `</span></code>), click <a href="/">here</a>.</p>
            </div>`;
        } else {
            document.getElementById("doc_ver_warning").remove();
        }
    });
</script>

<!-- End of Version Warning Banner -->

 
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
</style>
<style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }

    .output_area {
        max-height: 300px;
        overflow: auto;
    }

    .dataframe {
        background: #D7D7D7;
    }

    th {
        color:black;
    }
</style>

<script type="text/javascript">
    window.addEventListener('load', () => {
        const h1_element = document.getElementsByTagName("h1");
        h1_element[0].insertAdjacentHTML("afterend", `
        <p>
            <a style="background-color:white;color:black;padding:4px 12px;text-decoration:none;display:inline-block;border-radius:8px;box-shadow:0 2px 4px 0 rgba(0, 0, 0, 0.2), 0 3px 10px 0 rgba(0, 0, 0, 0.19)" href="https://colab.research.google.com/github/cleanlab/cleanlab-docs/blob/master/master/tutorials/token_classification.ipynb" target="_blank">
            <img src="https://colab.research.google.com/img/colab_favicon_256px.png" alt="" style="width:40px;height:40px;vertical-align:middle">
            <span style="vertical-align:middle">Run in Google Colab</span>
            </a>
        </p>
        `);
    })

</script><section id="Finding-Label-Errors-in-Token-Classification-Datasets">
<h1>Finding Label Errors in Token Classification Datasets<a class="headerlink" href="#Finding-Label-Errors-in-Token-Classification-Datasets" title="Permalink to this heading">#</a></h1>
<p>This tutorial shows how you can use cleanlab to find potential label errors in text datasets used for the NLP task of token classification. In token-classification, our data consists of a bunch of sentences (aka documents) in which every token (aka word) is labeled with one of K classes, and we train models to predict the class of each token in a new sentence. Example applications include part-of-speech-tagging or entity recognition, which is the focus on this tutorial. Here, we use CONLL-2003
named entity recognition dataset which contains 20,718 sentences and 301,361 tokens, where each token is labeled with one of the following classes:</p>
<ul class="simple">
<li><p>LOC (location entity)</p></li>
<li><p>PER (person entity)</p></li>
<li><p>ORG (organization entity)</p></li>
<li><p>MISC (miscellaneous other type of entity)</p></li>
<li><p>O (other type of word that does not correspond to an entity)</p></li>
</ul>
<p><strong>Overview of what we’ll do in this tutorial:</strong> - Identify potential token label issues using cleanlab’s <code class="docutils literal notranslate"><span class="pre">token_classification.filter.find_label_issues</span></code> method. - Rank sentences using cleanlab’s <code class="docutils literal notranslate"><span class="pre">token_classification.rank.get_label_quality_scores</span></code> method. - TODO: (Clean Learning) Train a more robust model by removing problematic sentences.</p>
<section id="1.-Install-required-dependencies-and-download-data">
<h2>1. Install required dependencies and download data<a class="headerlink" href="#1.-Install-required-dependencies-and-download-data" title="Permalink to this heading">#</a></h2>
<p>You can use <code class="docutils literal notranslate"><span class="pre">pip</span></code> to install all packages required for this tutorial as follows:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>!pip install cleanlab
</pre></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>wget -nc https://data.deepai.org/conll2003.zip <span class="o">&amp;&amp;</span> mkdir data
<span class="o">!</span>unzip conll2003.zip -d data/ <span class="o">&amp;&amp;</span> rm conll2003.zip
<span class="o">!</span>wget -nc <span class="s1">&#39;https://cleanlab-public.s3.amazonaws.com/TokenClassification/pred_probs.npz&#39;</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
--2022-09-06 23:01:56--  https://data.deepai.org/conll2003.zip
Resolving data.deepai.org (data.deepai.org)... 5.9.140.253
Connecting to data.deepai.org (data.deepai.org)|5.9.140.253|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 982975 (960K) [application/x-zip-compressed]
Saving to: ‘conll2003.zip’

conll2003.zip       100%[===================&gt;] 959.94K  2.09MB/s    in 0.4s

2022-09-06 23:01:57 (2.09 MB/s) - ‘conll2003.zip’ saved [982975/982975]

mkdir: cannot create directory ‘data’: File exists
Archive:  conll2003.zip
  inflating: data/metadata
  inflating: data/test.txt
  inflating: data/train.txt
  inflating: data/valid.txt
--2022-09-06 23:01:58--  https://cleanlab-public.s3.amazonaws.com/TokenClassification/pred_probs.npz
Resolving cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)... 54.231.234.241
Connecting to cleanlab-public.s3.amazonaws.com (cleanlab-public.s3.amazonaws.com)|54.231.234.241|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 17045998 (16M) [binary/octet-stream]
Saving to: ‘pred_probs.npz’

pred_probs.npz      100%[===================&gt;]  16.26M  --.-KB/s    in 0.1s

2022-09-06 23:01:58 (139 MB/s) - ‘pred_probs.npz’ saved [17045998/17045998]

</pre></div></div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">cleanlab.token_classification.filter</span> <span class="kn">import</span> <span class="n">find_label_issues</span>
<span class="kn">from</span> <span class="nn">cleanlab.token_classification.rank</span> <span class="kn">import</span> <span class="n">get_label_quality_scores</span><span class="p">,</span> <span class="n">issues_from_scores</span>
<span class="kn">from</span> <span class="nn">cleanlab.internal.token_classification_utils</span> <span class="kn">import</span> <span class="n">get_sentence</span><span class="p">,</span> <span class="n">filter_sentence</span><span class="p">,</span> <span class="n">mapping</span>
<span class="kn">from</span> <span class="nn">cleanlab.token_classification.summary</span> <span class="kn">import</span> <span class="n">display_issues</span><span class="p">,</span> <span class="n">common_label_issues</span><span class="p">,</span> <span class="n">filter_by_token</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="2.-Get-pred_probs,-labels-and-read-file">
<h2>2. Get <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code>, <code class="docutils literal notranslate"><span class="pre">labels</span></code> and read file<a class="headerlink" href="#2.-Get-pred_probs,-labels-and-read-file" title="Permalink to this heading">#</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> are out-of-sample model-predicted probabilities of the CoNLL-2003 dataset (including training, development, and testing dataset), obtained via cross-validation. To detect potential labels issues, we first get <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code>, which are both in nested-list format, such that:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> is a list of <code class="docutils literal notranslate"><span class="pre">np.arrays</span></code>, such that <code class="docutils literal notranslate"><span class="pre">pred_probs[i]</span></code> is the model-predicted probabilities for the tokens in the i’th sentence, and has shape <code class="docutils literal notranslate"><span class="pre">(N_i,</span> <span class="pre">K)</span></code>, where <code class="docutils literal notranslate"><span class="pre">N_i</span></code> is the number of word-level tokens of the <code class="docutils literal notranslate"><span class="pre">i</span></code>’th sentence. Each row of the matrix corresponds to a token <code class="docutils literal notranslate"><span class="pre">t</span></code> and contains the model-predicted probabilities that <code class="docutils literal notranslate"><span class="pre">t</span></code> belongs to each possible class, for each of the K classes. The columns must be ordered such that the probabilities correspond to class 0,
1, …, K-1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">labels</span></code> is a list of lists, such that <code class="docutils literal notranslate"><span class="pre">labels[i]</span></code> is a list of given token labels of the <code class="docutils literal notranslate"><span class="pre">i</span></code>’th sentence. For dataset with K classes, labels must be in 0, 1, …, K-1. All the classes (0, 1, …, and K-1) MUST be present in <code class="docutils literal notranslate"><span class="pre">labels[i]</span></code> for some <code class="docutils literal notranslate"><span class="pre">i</span></code>.</p></li>
</ul>
<p>Here, indicies are a tuple <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> unless otherwise specified, which refers to the <code class="docutils literal notranslate"><span class="pre">j</span></code>’th word-level token of the <code class="docutils literal notranslate"><span class="pre">i</span></code>’th sentence. Given that each sentence has different number of tokens, we store <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code> as <code class="docutils literal notranslate"><span class="pre">.npz</span></code> files, which can be easily converted to dictionaries. Use <code class="docutils literal notranslate"><span class="pre">read_npz</span></code> to retrieve <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> and <code class="docutils literal notranslate"><span class="pre">labels</span></code> in nested-list format.</p>
<details><p>Below is the code used to read the <code class="docutils literal notranslate"><span class="pre">.npz</span></code> file.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>def read_npz(filepath):
    data = dict(np.load(filepath))
    data = [data[str(i)] for i in range(len(data))]
    return data
</pre></div>
</div>
</details><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_probs</span> <span class="o">=</span> <span class="n">read_npz</span><span class="p">(</span><span class="s1">&#39;pred_probs.npz&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>As shown above, <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code> is a list of np.array. In our example, the first sentence has 9 given tokens and 5 class names.</p>
<p>Given that we would like to visualize the results, we first read the files. We obtain the sentences from the original files to display the word-level token label issues in context. <code class="docutils literal notranslate"><span class="pre">given_words</span></code> contains the word-level tokens in the dataset such that <code class="docutils literal notranslate"><span class="pre">given_words[i]</span></code> is a list of words of the <code class="docutils literal notranslate"><span class="pre">i</span></code>’th sentence; <code class="docutils literal notranslate"><span class="pre">given_labels</span></code> contains the given labels in the dataset such that <code class="docutils literal notranslate"><span class="pre">given_labels[i]</span></code> is a list of labels of the <code class="docutils literal notranslate"><span class="pre">i</span></code>th sentence. Note that in CoNLL-2003, the <code class="docutils literal notranslate"><span class="pre">B-</span></code> and <code class="docutils literal notranslate"><span class="pre">I-</span></code>
prefixes indicates whether the tokens are at the start of an entity, which are ignored in this tutorial. Therefore, we have two sets of entities:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>given_entities = [&#39;O&#39;, &#39;B-MISC&#39;, &#39;I-MISC&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;]
</pre></div>
</div>
<p>and</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>merge_entities = [&#39;O&#39;, &#39;MISC&#39;, &#39;PER&#39;, &#39;ORG&#39;, &#39;LOC&#39;]
</pre></div>
</div>
<details><p>Below is the code used for reading the files.</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>filepaths = [&#39;data/train.txt&#39;, &#39;data/valid.txt&#39;, &#39;data/test.txt&#39;]
given_entities = [&#39;O&#39;, &#39;B-MISC&#39;, &#39;I-MISC&#39;, &#39;B-PER&#39;, &#39;I-PER&#39;, &#39;B-ORG&#39;, &#39;I-ORG&#39;, &#39;B-LOC&#39;, &#39;I-LOC&#39;]
merged_entities = [&#39;O&#39;, &#39;MISC&#39;, &#39;PER&#39;, &#39;ORG&#39;, &#39;LOC&#39;]
entity_map = {entity: i for i, entity in enumerate(given_entities)}

def readfile(filepath, sep=&#39; &#39;):
    lines = open(filepath)

    data, sentence, label = [], [], []
    for line in lines:
        if len(line) == 0 or line.startswith(&#39;-DOCSTART&#39;) or line[0] == &#39;\n&#39;:
            if len(sentence) &gt; 0:
                data.append((sentence, label))
                sentence, label = [], []
            continue
        splits = line.split(sep)
        word = splits[0]
        if len(word) &gt; 0 and word[0].isalpha() and word.isupper():
            word = word[0] + word[1:].lower()
        sentence.append(word)
        label.append(entity_map[splits[-1][:-1]])

    if len(sentence) &gt; 0:
        data.append((sentence, label))

    given_words = [d[0] for d in data]
    given_labels = [d[1] for d in data]

    return given_words, given_labels

given_words, given_labels = [], []

for filepath in filepaths:
    words, label = readfile(filepath)
    given_words.extend(words)
    given_labels.extend(label)

sentences = list(map(get_sentence, given_words))

sentences, mask = filter_sentence(sentences)
given_words = [words for m, words in zip(mask, given_words) if m]
given_labels = [labels for m, labels in zip(mask, given_labels) if m]

maps = [0, 1, 1, 2, 2, 3, 3, 4, 4]
given_labels = [mapping(labels, maps) for labels in given_labels]
</pre></div>
</div>
</details><div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">readfile</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">):</span>
    <span class="n">lines</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>

    <span class="n">data</span><span class="p">,</span> <span class="n">sentence</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">line</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="s1">&#39;-DOCSTART&#39;</span><span class="p">)</span> <span class="ow">or</span> <span class="n">line</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sentence</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>
                <span class="n">sentence</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
            <span class="k">continue</span>
        <span class="n">splits</span> <span class="o">=</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">sep</span><span class="p">)</span>
        <span class="n">word</span> <span class="o">=</span> <span class="n">splits</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">word</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">isalpha</span><span class="p">()</span> <span class="ow">and</span> <span class="n">word</span><span class="o">.</span><span class="n">isupper</span><span class="p">():</span>
            <span class="n">word</span> <span class="o">=</span> <span class="n">word</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">word</span><span class="p">[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>
        <span class="n">sentence</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>
        <span class="n">label</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">entity_map</span><span class="p">[</span><span class="n">splits</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">data</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">sentence</span><span class="p">,</span> <span class="n">label</span><span class="p">))</span>

    <span class="n">given_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>
    <span class="n">given_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">data</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">given_words</span><span class="p">,</span> <span class="n">given_labels</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">given_words</span><span class="p">,</span> <span class="n">given_labels</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">filepath</span> <span class="ow">in</span> <span class="n">filepaths</span><span class="p">:</span>
    <span class="n">words</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="n">readfile</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
    <span class="n">given_words</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">words</span><span class="p">)</span>
    <span class="n">given_labels</span><span class="o">.</span><span class="n">extend</span><span class="p">(</span><span class="n">label</span><span class="p">)</span>

<span class="n">sentences</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">get_sentence</span><span class="p">,</span> <span class="n">given_words</span><span class="p">))</span>

<span class="n">sentences</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">filter_sentence</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span>
<span class="n">given_words</span> <span class="o">=</span> <span class="p">[</span><span class="n">words</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">words</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">given_words</span><span class="p">)</span> <span class="k">if</span> <span class="n">m</span><span class="p">]</span>
<span class="n">given_labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">labels</span> <span class="k">for</span> <span class="n">m</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">given_labels</span><span class="p">)</span> <span class="k">if</span> <span class="n">m</span><span class="p">]</span>

<span class="n">maps</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">mapping</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">maps</span><span class="p">)</span> <span class="k">for</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">given_labels</span><span class="p">]</span>
</pre></div>
</div>
</div>
<p>Here, we request the inputs to be in the following format:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">indices_to_preview</span> <span class="o">=</span> <span class="mi">3</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">indices_to_preview</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">sentences[</span><span class="si">%d</span><span class="s1">]:</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">sentences</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;labels[</span><span class="si">%d</span><span class="s1">]:</span><span class="se">\t</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;pred_probs[</span><span class="si">%d</span><span class="s1">]:</span><span class="se">\n</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">i</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">pred_probs</span><span class="p">[</span><span class="n">i</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>

sentences[0]:   Eu rejects German call to boycott British lamb.
labels[0]:      [3, 0, 1, 0, 0, 0, 1, 0, 0]
pred_probs[0]:
[[0.00030412 0.00023826 0.99936208 0.00007009 0.00002545]
 [0.99998795 0.00000401 0.00000218 0.00000455 0.00000131]
 [0.00000749 0.99996115 0.00001371 0.0000087  0.00000895]
 [0.99998936 0.00000382 0.00000178 0.00000366 0.00000137]
 [0.99999101 0.00000266 0.00000174 0.0000035  0.00000109]
 [0.99998768 0.00000482 0.00000202 0.00000438 0.0000011 ]
 [0.00000465 0.99996392 0.00001105 0.0000116  0.00000878]
 [0.99998671 0.00000364 0.00000213 0.00000472 0.00000281]
 [0.99999073 0.00000211 0.00000159 0.00000442 0.00000115]]

sentences[1]:   Peter Blackburn
labels[1]:      [2, 2]
pred_probs[1]:
[[0.00000358 0.00000529 0.99995623 0.000022   0.0000129 ]
 [0.0000024  0.00001812 0.99994141 0.00001645 0.00002162]]

sentences[2]:   Brussels 1996-08-22
labels[2]:      [4, 0]
pred_probs[2]:
[[0.00001172 0.00000821 0.00004661 0.0000618  0.99987167]
 [0.99999061 0.00000201 0.00000195 0.00000408 0.00000135]]
</pre></div></div>
</div>
</section>
<section id="3.-Use-cleanlab-to-find-potential-label-issues">
<h2>3. Use cleanlab to find potential label issues<a class="headerlink" href="#3.-Use-cleanlab-to-find-potential-label-issues" title="Permalink to this heading">#</a></h2>
<p>Based on the given labels and out-of-sample predicted probabilities, cleanlab can quickly help us identify label issues in our dataset. Here we request that the indices of the identified label issues be sorted by cleanlab’s self-confidence score, which measures the quality of each given label via the probability assigned to it in our model’s prediction. Here, <code class="docutils literal notranslate"><span class="pre">issues</span></code> is a list of tuples <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code>, which corresponds to the <code class="docutils literal notranslate"><span class="pre">j</span></code>’th token of the <code class="docutils literal notranslate"><span class="pre">i</span></code>’th sentence. These are the tokens
cleanlab thinks may be badly labeled in your dataset.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">issues</span> <span class="o">=</span> <span class="n">find_label_issues</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">,</span> <span class="n">return_indices_ranked_by</span><span class="o">=</span><span class="s1">&#39;self_confidence&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
2022-09-06 23:02:18.621650: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library &#39;libcudart.so.11.0&#39;; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/hostedtoolcache/Python/3.8.13/x64/lib
2022-09-06 23:02:18.621687: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
</pre></div></div>
</div>
</section>
<section id="4.-Most-likely-issues">
<h2>4. Most likely issues<a class="headerlink" href="#4.-Most-likely-issues" title="Permalink to this heading">#</a></h2>
<p>Let’s look at the top 20 examples cleanlab thinks are most likely to be incorrectly labeled.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">top</span> <span class="o">=</span> <span class="mi">20</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Cleanlab found </span><span class="si">%d</span><span class="s1"> potential label issues. &#39;</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">issues</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The top </span><span class="si">%d</span><span class="s1"> most likely label errors:&#39;</span> <span class="o">%</span> <span class="n">top</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">issues</span><span class="p">[:</span><span class="n">top</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Cleanlab found 2255 potential label issues.
The top 20 most likely label errors:
[(2907, 0), (19392, 0), (9962, 4), (8904, 30), (19303, 0), (12918, 0), (9256, 0), (11855, 20), (18392, 4), (20426, 28), (19402, 21), (14744, 15), (19371, 0), (4645, 2), (83, 9), (10331, 3), (9430, 10), (6143, 25), (18367, 0), (12914, 3)]
</pre></div></div>
</div>
<p>We show the top 20 potential label issues. Given that <code class="docutils literal notranslate"><span class="pre">O</span></code> and <code class="docutils literal notranslate"><span class="pre">MISC</span></code> are hard to distinguish and can sometimes be ambiguous, they are excluded from the examples below. They can be specified in the <code class="docutils literal notranslate"><span class="pre">exclude</span></code> argument, which is a list of tuples <code class="docutils literal notranslate"><span class="pre">(i,</span> <span class="pre">j)</span></code> such that tokens predicted as <code class="docutils literal notranslate"><span class="pre">merged_entities[j]</span></code> but labels as <code class="docutils literal notranslate"><span class="pre">merged_entities[i]</span></code> are ignored. In the following example, we ignore mislabels between <code class="docutils literal notranslate"><span class="pre">O</span></code> and <code class="docutils literal notranslate"><span class="pre">MISC</span></code>, which are indexed <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">display_issues</span><span class="p">(</span><span class="n">issues</span><span class="p">,</span> <span class="n">given_words</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">given_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
               <span class="n">exclude</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span> <span class="n">class_names</span><span class="o">=</span><span class="n">merged_entities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sentence 2907, token 0:
<span class="ansi-red-fg">Little</span> change from today&#39;s weather expected.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 19392, token 0:
<span class="ansi-red-fg">Let</span>&#39;s march together,&#34; Scalfaro, a northerner himself, said.
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 9962, token 4:
3. Nastja Rysich (<span class="ansi-red-fg">germany</span>) 3.75
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 8904, token 30:
The Spla has fought Khartoum&#39;s government forces in the south since 1983 for greater autonomy or independence of the mainly Christian and animist region from the Moslem, Arabised <span class="ansi-red-fg">north</span>.
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 12918, token 0:
<span class="ansi-red-fg">Mayor</span> Antonio Gonzalez Garcia, of the opposition Revolutionary Workers&#39; Party, said in Wednesday&#39;s letter that army troops recently raided several local farms, stole cattle and raped women.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 9256, token 0:
<span class="ansi-red-fg">Spring</span> Chg Hrw 12pct Chg White Chg
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 11855, token 20:
&#34; We have seen the photos but for the moment the palace has no comment,&#34; a spokeswoman for <span class="ansi-red-fg">Prince</span> Rainier told Reuters.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 18392, token 4:
Danila 28.5 16<span class="ansi-red-fg">/</span>12 Caribs/ up W224 Mobil.
Given label: O, predicted label according to provided pred_probs: LOC

Sentence 19402, token 21:
A Reuter consensus survey sees medical equipment group Radiometer reporting largely unchanged earnings when it publishes first half 19996/97 results next <span class="ansi-red-fg">Wednesday</span>.
Given label: ORG, predicted label according to provided pred_probs: O

Sentence 83, token 9:
Listing London Denoms (K) 1-10-100 Sale Limits <span class="ansi-red-fg">Us</span>/ Uk/ Jp/ Fr
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 10331, token 3:
Hapoel Haifa 3 <span class="ansi-red-fg">Maccabi</span> Tel Aviv 1
Given label: O, predicted label according to provided pred_probs: ORG

Sentence 9430, token 10:
The revered Roman Catholic nun was admitted to the Calcutta <span class="ansi-red-fg">hospital</span> a week ago with high fever and severe vomiting.
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 6143, token 25:
The embattled Afghan government said last week that the Kabul-Salang highway would be opened on Monday or Tuesday following talks with the Supreme Coordination Council <span class="ansi-red-fg">alliance</span> led by Jumbish-i-Milli movement of powerful opposition warlord General Abdul Rashid Dostum.
Given label: ORG, predicted label according to provided pred_probs: O

Sentence 18367, token 0:
<span class="ansi-red-fg">Can</span>/ U.s. Dollar Exchange Rate: 1.3570
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 12049, token 0:
<span class="ansi-red-fg">Born</span> in 1937 in the central province of Anhui, Dai came to Shanghai as a student and remained in the city as a prolific author and teacher of Chinese.
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 16764, token 7:
1990 - British historian Alan John Percivale <span class="ansi-red-fg">(</span>A.j.p.) Taylor died.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 20446, token 0:
<span class="ansi-red-fg">Pace</span> bowler Ian Harvey claimed three for 81 for Victoria.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 15514, token 16:
But one must not forget that the Osce only has limited powers there,&#34; said <span class="ansi-red-fg">Cotti</span>, who is also the Swiss foreign minister.&#34;
Given label: O, predicted label according to provided pred_probs: PER

Sentence 7525, token 12:
Specter met Crown Prince Abdullah and Minister of Defence and Aviation Prince <span class="ansi-red-fg">Sultan</span> in Jeddah, Saudi state television and the official Saudi Press Agency reported.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 2288, token 0:
<span class="ansi-red-fg">Sporting</span> his customary bright green outfit, the U.s. champion clocked 10.03 seconds despite damp conditions to take the scalp of Canada&#39;s reigning Olympic champion Donovan Bailey, 1992 champion Linford Christie of Britain and American 1984 and 1988 champion Carl Lewis.
Given label: ORG, predicted label according to provided pred_probs: O

</pre></div></div>
</div>
<p>More than half of the potential label issues correspond to tokens that are incorrectly labeled. As shown above, some examples are ambigious and require manual checking. Observe that there are some edge cases such as tokens simply being punctuations such as <code class="docutils literal notranslate"><span class="pre">/</span></code> and <code class="docutils literal notranslate"><span class="pre">(</span></code>.</p>
</section>
<section id="4.-Most-common-word-level-token-mislabels">
<h2>4. Most common word-level token mislabels<a class="headerlink" href="#4.-Most-common-word-level-token-mislabels" title="Permalink to this heading">#</a></h2>
<p>It may be useful to examine the most common word-level token mislabels.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">info</span> <span class="o">=</span> <span class="n">common_label_issues</span><span class="p">(</span><span class="n">issues</span><span class="p">,</span> <span class="n">given_words</span><span class="p">,</span>
                           <span class="n">labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
                           <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span>
                           <span class="n">class_names</span><span class="o">=</span><span class="n">merged_entities</span><span class="p">,</span>
                           <span class="n">exclude</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)])</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Token &#39;/&#39; is potentially mislabeled 42 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `O` but predicted to actually be class `LOC` 36 times
labeled as class `O` but predicted to actually be class `PER` 4 times
labeled as class `O` but predicted to actually be class `ORG` 2 times

Token &#39;Chicago&#39; is potentially mislabeled 27 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 22 times
labeled as class `LOC` but predicted to actually be class `ORG` 3 times
labeled as class `MISC` but predicted to actually be class `ORG` 2 times

Token &#39;U.s.&#39; is potentially mislabeled 21 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `LOC` but predicted to actually be class `ORG` 8 times
labeled as class `ORG` but predicted to actually be class `LOC` 6 times
labeled as class `LOC` but predicted to actually be class `O` 3 times
labeled as class `LOC` but predicted to actually be class `MISC` 2 times
labeled as class `MISC` but predicted to actually be class `LOC` 1 times
labeled as class `MISC` but predicted to actually be class `ORG` 1 times

Token &#39;Digest&#39; is potentially mislabeled 20 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `O` but predicted to actually be class `ORG` 20 times

Token &#39;Press&#39; is potentially mislabeled 20 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `O` but predicted to actually be class `ORG` 20 times

Token &#39;New&#39; is potentially mislabeled 17 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 13 times
labeled as class `LOC` but predicted to actually be class `ORG` 2 times
labeled as class `O` but predicted to actually be class `ORG` 1 times
labeled as class `MISC` but predicted to actually be class `LOC` 1 times

Token &#39;and&#39; is potentially mislabeled 16 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `O` 7 times
labeled as class `O` but predicted to actually be class `ORG` 5 times
labeled as class `O` but predicted to actually be class `LOC` 3 times
labeled as class `MISC` but predicted to actually be class `ORG` 1 times

Token &#39;Philadelphia&#39; is potentially mislabeled 15 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 14 times
labeled as class `LOC` but predicted to actually be class `ORG` 1 times

Token &#39;Usda&#39; is potentially mislabeled 13 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 7 times
labeled as class `ORG` but predicted to actually be class `PER` 5 times
labeled as class `ORG` but predicted to actually be class `MISC` 1 times

Token &#39;York&#39; is potentially mislabeled 12 times throughout the dataset
---------------------------------------------------------------------------------------
labeled as class `ORG` but predicted to actually be class `LOC` 11 times
labeled as class `LOC` but predicted to actually be class `ORG` 1 times

</pre></div></div>
</div>
<p>The above printed information is also stored as a DataFrame <code class="docutils literal notranslate"><span class="pre">info</span></code>, sorted by the number of mislabels in descending order.</p>
</section>
<section id="5.-Find-issue-sentences-with-particular-word">
<h2>5. Find issue sentences with particular word<a class="headerlink" href="#5.-Find-issue-sentences-with-particular-word" title="Permalink to this heading">#</a></h2>
<p>Call <code class="docutils literal notranslate"><span class="pre">search_token</span></code> to examine the token label issues of a specific token.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">token_issues</span> <span class="o">=</span> <span class="n">filter_by_token</span><span class="p">(</span><span class="s1">&#39;United&#39;</span><span class="p">,</span> <span class="n">issues</span><span class="p">,</span> <span class="n">given_words</span><span class="p">)</span>
<span class="n">display_issues</span><span class="p">(</span><span class="n">token_issues</span><span class="p">,</span> <span class="n">given_words</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">given_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
               <span class="n">exclude</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span> <span class="n">class_names</span><span class="o">=</span><span class="n">merged_entities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sentence 471, token 8:
Soccer - Keane Signs Four-year Contract With Manchester <span class="ansi-red-fg">United</span>.
Given label: LOC, predicted label according to provided pred_probs: ORG

Sentence 19072, token 5:
The Humane Society of the <span class="ansi-red-fg">United</span> States estimates that between 500,000 and one million bites are delivered by dogs each year, more than half of which are suffered by children.
Given label: LOC, predicted label according to provided pred_probs: ORG

Sentence 19910, token 5:
His father Clarence Woolmer represented <span class="ansi-red-fg">United</span> Province, now renamed Uttar Pradesh, in India&#39;s Ranji Trophy national championship and captained the state during 1949.
Given label: LOC, predicted label according to provided pred_probs: ORG

Sentence 15658, token 0:
<span class="ansi-red-fg">United</span> Nations 1996-08-29
Given label: ORG, predicted label according to provided pred_probs: LOC

Sentence 19879, token 1:
1. <span class="ansi-red-fg">United</span> States Iii (Brian Shimer, Randy Jones) one
Given label: ORG, predicted label according to provided pred_probs: LOC

Sentence 19104, token 0:
<span class="ansi-red-fg">United</span> Nations 1996-12-06
Given label: ORG, predicted label according to provided pred_probs: LOC

</pre></div></div>
</div>
</section>
<section id="6.-Sentence-label-quality-score">
<h2>6. Sentence label quality score<a class="headerlink" href="#6.-Sentence-label-quality-score" title="Permalink to this heading">#</a></h2>
<p>Cleanlab can analyze every label in the dataset and provide a numerical score for each sentence. The score ranges between 0 and 1: a lower score indicates that the sentence is more likely to contain at least one error.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span><span class="p">,</span> <span class="n">token_scores</span> <span class="o">=</span> <span class="n">get_label_quality_scores</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">pred_probs</span><span class="p">)</span>
<span class="n">issues</span> <span class="o">=</span> <span class="n">issues_from_scores</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">token_scores</span><span class="o">=</span><span class="n">token_scores</span><span class="p">)</span>
<span class="n">display_issues</span><span class="p">(</span><span class="n">issues</span><span class="p">,</span> <span class="n">given_words</span><span class="p">,</span> <span class="n">pred_probs</span><span class="o">=</span><span class="n">pred_probs</span><span class="p">,</span> <span class="n">given_labels</span><span class="o">=</span><span class="n">labels</span><span class="p">,</span>
               <span class="n">exclude</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)],</span> <span class="n">class_names</span><span class="o">=</span><span class="n">merged_entities</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Sentence 2907, token 0:
<span class="ansi-red-fg">Little</span> change from today&#39;s weather expected.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 19392, token 0:
<span class="ansi-red-fg">Let</span>&#39;s march together,&#34; Scalfaro, a northerner himself, said.
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 9962, token 4:
3. Nastja Rysich (<span class="ansi-red-fg">germany</span>) 3.75
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 8904, token 30:
The Spla has fought Khartoum&#39;s government forces in the south since 1983 for greater autonomy or independence of the mainly Christian and animist region from the Moslem, Arabised <span class="ansi-red-fg">north</span>.
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 12918, token 0:
<span class="ansi-red-fg">Mayor</span> Antonio Gonzalez Garcia, of the opposition Revolutionary Workers&#39; Party, said in Wednesday&#39;s letter that army troops recently raided several local farms, stole cattle and raped women.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 9256, token 0:
<span class="ansi-red-fg">Spring</span> Chg Hrw 12pct Chg White Chg
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 11855, token 20:
&#34; We have seen the photos but for the moment the palace has no comment,&#34; a spokeswoman for <span class="ansi-red-fg">Prince</span> Rainier told Reuters.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 18392, token 4:
Danila 28.5 16<span class="ansi-red-fg">/</span>12 Caribs/ up W224 Mobil.
Given label: O, predicted label according to provided pred_probs: LOC

Sentence 19402, token 21:
A Reuter consensus survey sees medical equipment group Radiometer reporting largely unchanged earnings when it publishes first half 19996/97 results next <span class="ansi-red-fg">Wednesday</span>.
Given label: ORG, predicted label according to provided pred_probs: O

Sentence 83, token 9:
Listing London Denoms (K) 1-10-100 Sale Limits <span class="ansi-red-fg">Us</span>/ Uk/ Jp/ Fr
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 10331, token 3:
Hapoel Haifa 3 <span class="ansi-red-fg">Maccabi</span> Tel Aviv 1
Given label: O, predicted label according to provided pred_probs: ORG

Sentence 9430, token 10:
The revered Roman Catholic nun was admitted to the Calcutta <span class="ansi-red-fg">hospital</span> a week ago with high fever and severe vomiting.
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 6143, token 25:
The embattled Afghan government said last week that the Kabul-Salang highway would be opened on Monday or Tuesday following talks with the Supreme Coordination Council <span class="ansi-red-fg">alliance</span> led by Jumbish-i-Milli movement of powerful opposition warlord General Abdul Rashid Dostum.
Given label: ORG, predicted label according to provided pred_probs: O

Sentence 18367, token 0:
<span class="ansi-red-fg">Can</span>/ U.s. Dollar Exchange Rate: 1.3570
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 12049, token 0:
<span class="ansi-red-fg">Born</span> in 1937 in the central province of Anhui, Dai came to Shanghai as a student and remained in the city as a prolific author and teacher of Chinese.
Given label: LOC, predicted label according to provided pred_probs: O

Sentence 16764, token 7:
1990 - British historian Alan John Percivale <span class="ansi-red-fg">(</span>A.j.p.) Taylor died.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 20446, token 0:
<span class="ansi-red-fg">Pace</span> bowler Ian Harvey claimed three for 81 for Victoria.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 15514, token 16:
But one must not forget that the Osce only has limited powers there,&#34; said <span class="ansi-red-fg">Cotti</span>, who is also the Swiss foreign minister.&#34;
Given label: O, predicted label according to provided pred_probs: PER

Sentence 7525, token 12:
Specter met Crown Prince Abdullah and Minister of Defence and Aviation Prince <span class="ansi-red-fg">Sultan</span> in Jeddah, Saudi state television and the official Saudi Press Agency reported.
Given label: PER, predicted label according to provided pred_probs: O

Sentence 2288, token 0:
<span class="ansi-red-fg">Sporting</span> his customary bright green outfit, the U.s. champion clocked 10.03 seconds despite damp conditions to take the scalp of Canada&#39;s reigning Olympic champion Donovan Bailey, 1992 champion Linford Christie of Britain and American 1984 and 1988 champion Carl Lewis.
Given label: ORG, predicted label according to provided pred_probs: O

</pre></div></div>
</div>
</section>
</section>
 
        </article>
      </div>
      <footer>
         
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, Cleanlab Inc.
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/cleanlab/cleanlab" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        

<script type="text/javascript">
    window.addEventListener("load", () => {
        let elements = document.getElementsByClassName("left-details");

        elements[0].insertAdjacentHTML(
            "afterbegin",
            `<code class="docutils literal notranslate"><span class="pre">cleanlab</span></code> is distributed on <a href="https://pypi.org/project/cleanlab/">PyPI</a> and <a href="https://anaconda.org/conda-forge/cleanlab">conda</a>.`
        );
    });
</script>


      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            Contents
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Finding Label Errors in Token Classification Datasets</a><ul>
<li><a class="reference internal" href="#1.-Install-required-dependencies-and-download-data">1. Install required dependencies and download data</a></li>
<li><a class="reference internal" href="#2.-Get-pred_probs,-labels-and-read-file">2. Get <code class="docutils literal notranslate"><span class="pre">pred_probs</span></code>, <code class="docutils literal notranslate"><span class="pre">labels</span></code> and read file</a></li>
<li><a class="reference internal" href="#3.-Use-cleanlab-to-find-potential-label-issues">3. Use cleanlab to find potential label issues</a></li>
<li><a class="reference internal" href="#4.-Most-likely-issues">4. Most likely issues</a></li>
<li><a class="reference internal" href="#4.-Most-common-word-level-token-mislabels">4. Most common word-level token mislabels</a></li>
<li><a class="reference internal" href="#5.-Find-issue-sentences-with-particular-word">5. Find issue sentences with particular word</a></li>
<li><a class="reference internal" href="#6.-Sentence-label-quality-score">6. Sentence label quality score</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    
<script async defer src="https://buttons.github.io/buttons.js"></script>
</body>
</html>